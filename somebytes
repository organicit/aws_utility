#!/usr/bin/env python3
import boto3
import argparse
import requests
import os
import sys
import math
import datetime
import time
from random import shuffle
import shutil


'''
somebytes allows user to create random text files and upload them to a predefined, or user defined S3 bucket. It also
allows its user the ability to query a predefined, or user defined S3 bucket and retrieve files based on a minimum size

example usage:

somebytes -c 10 'Mybucket'

somebytes -l 1024 'yourbucket'
'''

PROG = sys.argv[0]
s3 = boto3.resource('s3', region_name='us-east-1')
tempfile_dir = os.getcwd() + '/files/'

arg_desc = 'create or query objects in an AWS S3 bucket'
parser = argparse.ArgumentParser(prog= PROG, description=arg_desc)
group = parser.add_mutually_exclusive_group(required=True)
group.add_argument('-c', nargs='+',
                       help='Set the number of S3 objects to create. The default is 10')
group.add_argument('-l', nargs='+',
                       help='provide integer value for number of bytes contained in s3 object being queried for. Minimum should be 1024 bytes')
args = parser.parse_args()

def get_ipsum():
    try:
        r = requests.get('https://loripsum.net/api/10/long/plaintext')
        seed_ipsum = r.text
        return seed_ipsum
    except requests.exceptions.RequestException as e:
        print(e)
        sys.exit(1)

def generate_s3files(num_s3_objects):
    ipsum = get_ipsum()
    if not os.path.exists(tempfile_dir):
        os.makedirs(tempfile_dir)

    for num in range(num_s3_objects):
        ipsum_list = ipsum.split()
        shuffle(ipsum_list)
        new_ipsum = ' '.join(ipsum_list)
        ts = time.time()
        filename = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d-%H-%M-%S' + str(num) + '.txt')
        file = open(tempfile_dir + filename, "w")
        file.write(new_ipsum)
        file.close()

def uploadto_s3(s3bucket):

    file_dir = 'files/'

    for file in os.listdir(file_dir):
        s3.meta.client.upload_file(file_dir + file, s3bucket, file)

    shutil.rmtree(tempfile_dir)

def check_bucket(s3_bucket):
    try:
        s3.meta.client.list_objects(Bucket=s3_bucket)
    except:
        print('Could not find bucket. Creating it now with basic security.  Please review')
        s3.create_bucket(Bucket=s3_bucket)

def query_s3objects(byte_count, s3_bucket):
    bucket_contents = s3.meta.client.list_objects(Bucket=s3_bucket)
    content_list = bucket_contents['Contents']
    for item in [i for i in content_list if i['Size'] > byte_count ]:
        print("Key_Name: {}, Size: {}".format(item['Key'], item['Size']))

if args.l == None:
    c_num = len(args.c)
    num_s3_objects = int(args.c[0])
    if c_num == 2:
        s3_bucket = args.c[1]
    else:
        if "SOMEBYTES_BUCKET" in os.environ:
            s3_bucket = os.getenv("SOMEBYTES_BUCKET")
        else:
            print('No Bucket was provided or found in your environment variables')
            sys.exit(1)

    generate_s3files(num_s3_objects)
    check_bucket(s3_bucket)
    uploadto_s3(s3_bucket)


else:
    l_num = len(args.l)
    num_query_bytes = int(args.l[0])
    if l_num == 2:
        s3_bucket = args.l[1]
    else:
        if "SOMEBYTES_BUCKET" in os.environ:
            s3_bucket = os.getenv("SOMEBYTES_BUCKET")
        else:
            print('No Bucket was provided or found in your environment variables')
            sys.exit(1)

    query_s3objects(num_query_bytes, s3_bucket)
